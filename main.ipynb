{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "from torch import nn \n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset, random_split \n",
    "\n",
    "import scipy.signal as signal\n",
    "import scipy.stats as stats\n",
    "\n",
    "from helper import hrv_feature_extractor\n",
    "from helper import new_coral_training\n",
    "from helper import new_compute_mae_and_mse\n",
    "from dataset import personal_standarlization\n",
    "from model import MyDataset\n",
    "from model import MyDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bee74a",
   "metadata": {},
   "source": [
    "## HRV feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a054f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read ECG files\n",
    "data = pd.read_csv(\"Biovid/input_ecg_part_a.csv\", index_col = 0)\n",
    "raw_signal = np.array(data.iloc[:,:-1])\n",
    "biovid_label = np.array(data.iloc[:,-1])\n",
    "print(\"ECG signal shape: \", raw_signal.shape)\n",
    "\n",
    "biovid_subject_id = np.repeat(range(87), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2540e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv_feature = hrv_feature_extractor(raw_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43006590",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv_feature = pd.DataFrame(hrv_feature)\n",
    "hrv_feature.rename(columns={0: 'Value1', 1: 'Value2', 2: 'Value3',3: 'Value4',4: 'Value5'}, inplace=True)\n",
    "hrv_feature[\"id\"] = pd.Series(biovid_subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f4debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by ID and calculating statistical indicators\n",
    "grouped = hrv_feature.groupby('id')\n",
    "\n",
    "result = grouped.agg({'Value1': ['min', 'max', 'var', 'std', 'mad', 'mean'],\n",
    "                      'Value2': ['min', 'max', 'var', 'std', 'mad', 'mean'],\n",
    "                      'Value3': ['min', 'max', 'var', 'std', 'mad', 'mean'],\n",
    "                     'Value4': ['min', 'max', 'var', 'std', 'mad', 'mean'],\n",
    "                     'Value5': ['min', 'max', 'var', 'std', 'mad', 'mean']})\n",
    "\n",
    "# Rename columns\n",
    "result.columns = result.columns.map('_'.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "hrv = hrv_feature.iloc[:, :-1]\n",
    "hrv_filled = hrv.fillna(hrv.mean())\n",
    "dataframe_scaled = scaler.fit_transform(hrv_filled)\n",
    "\n",
    "# Initialize the PCA model, set the number of principal components to be extracted to 1\n",
    "pca = PCA(n_components=1)\n",
    "\n",
    "# Use PCA model to fit the data and get the converted result (i.e. PC1).\n",
    "dataframe_transformed = pca.fit_transform(dataframe_scaled)\n",
    "\n",
    "# Convert the converted result into a DataFrame and give the corresponding column names.\n",
    "dataframe_pc1 = pd.DataFrame(dataframe_transformed, columns=['PC1'])\n",
    "\n",
    "dataframe_pc1[\"id\"] = pd.Series(biovid_subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13272da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by ID and calculate statistical indicators\n",
    "grouped = dataframe_pc1.groupby('id')\n",
    "\n",
    "result = grouped.agg({'PC1': ['min', 'max', 'var', 'std', 'mad', 'mean']})\n",
    "\n",
    "# Rename the column name\n",
    "result.columns = result.columns.map('_'.join)\n",
    "\n",
    "# Print results\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ca1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['cov'] = result['PC1_std'] / result['PC1_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d450503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def scale_with_tanh(vector, a, b):\n",
    "    scaled_vector = (np.tanh(vector) + 1) * (b - a) / 2 + a\n",
    "    return scaled_vector\n",
    "\n",
    "# Scale using the Tanh function to scale the data range to [0.9, 1.1]\n",
    "scaled_vector = scale_with_tanh(result['cov'], a=0.9, b=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f6090",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a918fa7",
   "metadata": {},
   "source": [
    "## Biovid data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read files\n",
    "data = pd.read_csv(\"Biovid/input_gsr_part_a.csv\", index_col = 0)\n",
    "raw_signal_gsr = np.array(data.iloc[:,:-1])\n",
    "biovid_label_gsr = np.array(data.iloc[:,-1])\n",
    "total_valid_file = [i for i in range(87)]\n",
    "subject_id = torch.tensor(biovid_subject_id)\n",
    "\n",
    "Biovid_gsr_standarlizad = personal_standarlization(pd.DataFrame(raw_signal_gsr), biovid_subject_id)\n",
    "\n",
    "standarlized_eda_tensor = torch.tensor(Biovid_gsr_standarlizad.values, dtype=torch.float32)\n",
    "\n",
    "data = []\n",
    "for i in range(standarlized_eda_tensor.shape[0]):\n",
    "    sample = {\n",
    "        'subject_id': biovid_subject_id[i],  # Assuming unique subject_ids starting from 0\n",
    "        'signal': standarlized_eda_tensor[i],\n",
    "        'label': biovid_label_gsr[i],\n",
    "    }\n",
    "    data.append(sample)\n",
    "\n",
    "\n",
    "ds_biovid = MyDataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4760bf",
   "metadata": {},
   "source": [
    "## Cross validation (let one subject out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577fe85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mae = []\n",
    "total_mse = []\n",
    "\n",
    "for subject in total_valid_file:\n",
    "    print(\"current subject for testing: \", subject)\n",
    "    test_mask = (subject_id == subject)\n",
    "    training_mask = (subject_id != subject)\n",
    "\n",
    "    heldout_data = Subset(ds_biovid, np.where(test_mask)[0])\n",
    "    training_data = Subset(ds_biovid, np.where(training_mask)[0])\n",
    "\n",
    "    # using dataloader \n",
    "    dl_train = MyDataLoader(training_data,batch_size = 32)\n",
    "    dl_val = MyDataLoader(heldout_data,batch_size = 32)\n",
    "    \n",
    "    Coral_model = new_coral_training(dl_train, 5, scaled_vector, important_weight_type = \"hard5\", n_epochs=20)\n",
    "    \n",
    "    # Evaluate target data\n",
    "    test_mae, test_mse = new_compute_mae_and_mse(Coral_model, dl_val)\n",
    "    total_mae.append(test_mae)\n",
    "    total_mse.append(test_mse)\n",
    "    \n",
    "print(\"LOSO MAE: \",np.mean(total_mae))\n",
    "print(\"LOSO MSE: \",np.mean(total_mse))\n",
    "print(\"LOSO RMSE: \", np.sqrt(np.mean(total_mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c4caef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
